{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day2_Programming_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Gn8fZczhArLvLg41z2a-wy1eR7oUVvUU",
      "authorship_tag": "ABX9TyMPfm+Es3zjTaW6lOFsZihA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A8Y/StudyAI/blob/master/Day2_Programming_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l9TAaS4o84_",
        "colab_type": "text"
      },
      "source": [
        "# Day2 演習\n",
        "\n",
        "考察とまとめ：\n",
        "\n",
        "演習1：\n",
        "\n",
        "XavierとReLuを組み合わせたところSigmoidより精度が上がった\n",
        "\n",
        "HeとSigmoidにすると学習の精度が大幅に落ちた。\n",
        "\n",
        "\n",
        "\n",
        "演習2:\n",
        "\n",
        "\n",
        "\n",
        "演習3：\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUEGFTi4ndOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Pythonライブラリ基礎講座/DNN_code_colab_ver200425')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCp4B1-Nvd2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from data.mnist import load_mnist\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# mnistをロード\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "train_size = len(x_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yF0ymWmwpBE",
        "colab_type": "text"
      },
      "source": [
        "# 重みを初期化\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_3V_1IXucdc",
        "colab_type": "text"
      },
      "source": [
        "## [try1] 活性化関数や重みの初期値を変えてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhsvftcKiH9a",
        "colab_type": "text"
      },
      "source": [
        "## Xavier\n",
        "\n",
        "*   活性化関数をReLUに変更\n",
        "*   中間層ノード数をそれぞれ100と30に変更\n",
        "\n",
        "結果：\n",
        "\n",
        "Sigmoid活性化関数より精度が上がった\n",
        "\n",
        "各隠れ層のノードを二倍にしたが精度にほとんど変化なし"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBHwNp_ssjOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "5c6ccb4b-6521-4565-eefd-62811004d733"
      },
      "source": [
        "# Xavier-ReLu  784-100-30-10\n",
        "\n",
        "#入力層サイズ\n",
        "input_layer_size = 784\n",
        "#中間層サイズ\n",
        "hidden_layer_1_size = 50\n",
        "hidden_layer_2_size = 20\n",
        "#出力層サイズ\n",
        "output_layer_size = 10\n",
        "# 繰り返し数\n",
        "iters_num = 2000\n",
        "# ミニバッチサイズ\n",
        "batch_size = 100\n",
        "# 学習率\n",
        "learning_rate = 0.1\n",
        "# 描写頻度\n",
        "plot_interval=10\n",
        "\n",
        "# 初期設定\n",
        "def init_network():\n",
        "    network = {} \n",
        "    \n",
        "    ###########  変更箇所  ##############\n",
        "    \n",
        "    # Xavierの初期値\n",
        "    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / (np.sqrt(input_layer_size))\n",
        "    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / (np.sqrt(hidden_layer_1_size))\n",
        "    network['W3'] = np.random.randn(hidden_layer_2_size, output_layer_size) / (np.sqrt(hidden_layer_2_size))\n",
        "    \n",
        "    #################################\n",
        "    \n",
        "    network['b1'] = np.zeros(hidden_layer_1_size)\n",
        "    network['b2'] = np.zeros(hidden_layer_2_size)\n",
        "    network['b3'] = np.zeros(output_layer_size)\n",
        "\n",
        "    return network\n",
        "\n",
        "# 順伝播\n",
        "def forward(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "#    hidden_f = functions.sigmoid\n",
        "    hidden_f = functions.relu\n",
        "    \n",
        "    u1 =  np.dot(x, W1) + b1\n",
        "    z1 = hidden_f(u1)\n",
        "    u2 =  np.dot(z1, W2) + b2\n",
        "    z2 = hidden_f(u2)\n",
        "    u3 =  np.dot(z2, W3) + b3\n",
        "    y = functions.softmax(u3)\n",
        " \n",
        "    return z1, z2, y\n",
        "\n",
        "# 誤差逆伝播\n",
        "def backward(x, d, z1, z2, y):\n",
        "    grad = {}\n",
        "    \n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "    hidden_d_f = functions.d_relu\n",
        "    #hidden_d_f = functions.d_sigmoid\n",
        "    \n",
        "    # 出力層でのデルタ\n",
        "    delta3 = functions.d_softmax_with_loss(d, y)\n",
        "    # b3の勾配\n",
        "    grad['b3'] = np.sum(delta3, axis=0)\n",
        "    # W3の勾配\n",
        "    grad['W3'] = np.dot(z2.T, delta3)\n",
        "    # 2層でのデルタ\n",
        "    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n",
        "    # b2の勾配\n",
        "    grad['b2'] = np.sum(delta2, axis=0)\n",
        "    # W2の勾配\n",
        "    grad['W2'] = np.dot(z1.T, delta2)\n",
        "    # 1層でのデルタ\n",
        "    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n",
        "    # b1の勾配\n",
        "    grad['b1'] = np.sum(delta1, axis=0)\n",
        "    # W1の勾配\n",
        "    grad['W1'] = np.dot(x.T, delta1)\n",
        "\n",
        "    return grad\n",
        "\n",
        "# パラメータの初期化\n",
        "network = init_network()\n",
        "\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "# 正答率\n",
        "def accuracy(x, d):\n",
        "    z1, z2, y = forward(network, x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    if d.ndim != 1 : d = np.argmax(d, axis=1)\n",
        "    accuracy = np.sum(y == d) / float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # ランダムにバッチを取得    \n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    # ミニバッチに対応する教師訓練画像データを取得    \n",
        "    x_batch = x_train[batch_mask]\n",
        "    # ミニバッチに対応する訓練正解ラベルデータを取得する\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "\n",
        "    \n",
        "    z1, z2, y = forward(network, x_batch)\n",
        "    grad = backward(x_batch, d_batch, z1, z2, y)\n",
        "\n",
        "    if (i+1)%plot_interval==0:\n",
        "        accr_test = accuracy(x_test, d_test)\n",
        "        accuracies_test.append(accr_test)\n",
        "        \n",
        "        accr_train = accuracy(x_batch, d_batch)\n",
        "        accuracies_train.append(accr_train)\n",
        "\n",
        "#        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        " #       print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n",
        "        \n",
        "    # パラメータに勾配適用\n",
        "    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n",
        "        network[key]  -= learning_rate * grad[key]\n",
        "\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-eb342a13a173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mplot_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0maccr_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0maccuracies_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccr_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-eb342a13a173>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(x, d)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# 正答率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-eb342a13a173>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(network, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mhidden_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mu1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mu2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZXUueYf7Js6",
        "colab_type": "text"
      },
      "source": [
        "## He\n",
        "\n",
        "Sigmoidに変えてみる\n",
        "\n",
        "結果：\n",
        "\n",
        "HeはReLu関数に特化した重みの最適法なので予想道り精度は悪化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mw0zvpxvQrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# He-Sigmoid 784-100-30-10\n",
        "\n",
        "# 重み初期値補正係数\n",
        "wieght_init = 0.01\n",
        "#入力層サイズ\n",
        "input_layer_size = 784\n",
        "#中間層サイズ\n",
        "hidden_layer_1_size = 100\n",
        "hidden_layer_2_size = 30\n",
        "\n",
        "#出力層サイズ\n",
        "output_layer_size = 10\n",
        "# 繰り返し数\n",
        "iters_num = 2000\n",
        "# ミニバッチサイズ\n",
        "batch_size = 100\n",
        "# 学習率\n",
        "learning_rate = 0.1\n",
        "# 描写頻度\n",
        "plot_interval=10\n",
        "\n",
        "# 初期設定\n",
        "def init_network():\n",
        "    network = {} \n",
        "\n",
        "    ###########  変更箇所  ##############\n",
        "\n",
        "    # Heの初期値\n",
        "    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / np.sqrt(input_layer_size) * np.sqrt(2)\n",
        "    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / np.sqrt(hidden_layer_1_size) * np.sqrt(2)\n",
        "    network['W3'] = np.random.randn(hidden_layer_2_size, output_layer_size) / np.sqrt(hidden_layer_2_size) * np.sqrt(2)\n",
        "        \n",
        "    #################################\n",
        "    \n",
        "    network['b1'] = np.zeros(hidden_layer_1_size)\n",
        "    network['b2'] = np.zeros(hidden_layer_2_size)\n",
        "    network['b3'] = np.zeros(output_layer_size)\n",
        "\n",
        "    return network\n",
        "\n",
        "# 順伝播\n",
        "def forward(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    ###########  変更箇所  ##############\n",
        "    \n",
        " #   hidden_f = functions.relu\n",
        "    hidden_f = functions.sigmoid\n",
        "    \n",
        "    #################################\n",
        "    \n",
        "    u1 =  np.dot(x, W1) + b1\n",
        "    z1 = hidden_f(u1)\n",
        "    u2 =  np.dot(z1, W2) + b2\n",
        "    z2 = hidden_f(u2)\n",
        "    u3 =  np.dot(z2, W3) + b3\n",
        "    y = functions.softmax(u3)\n",
        " \n",
        "    return z1, z2, y\n",
        "\n",
        "# 誤差逆伝播\n",
        "def backward(x, d, z1, z2, y):\n",
        "    grad = {}\n",
        "    \n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "    \n",
        "    ###########  変更箇所  ##############\n",
        "    \n",
        "    hidden_d_f = functions.d_sigmoid\n",
        "   # hidden_d_f = functions.d_relu\n",
        "\n",
        "    #################################\n",
        "    \n",
        "    # 出力層でのデルタ\n",
        "    delta3 = functions.d_softmax_with_loss(d, y)\n",
        "    # b3の勾配\n",
        "    grad['b3'] = np.sum(delta3, axis=0)\n",
        "    # W3の勾配\n",
        "    grad['W3'] = np.dot(z2.T, delta3)\n",
        "    # 2層でのデルタ\n",
        "    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n",
        "    # b2の勾配\n",
        "    grad['b2'] = np.sum(delta2, axis=0)\n",
        "    # W2の勾配\n",
        "    grad['W2'] = np.dot(z1.T, delta2)\n",
        "    # 1層でのデルタ\n",
        "    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n",
        "    # b1の勾配\n",
        "    grad['b1'] = np.sum(delta1, axis=0)\n",
        "    # W1の勾配\n",
        "    grad['W1'] = np.dot(x.T, delta1)\n",
        "\n",
        "    return grad\n",
        "\n",
        "# パラメータの初期化\n",
        "network = init_network()\n",
        "\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "# 正答率\n",
        "def accuracy(x, d):\n",
        "    z1, z2, y = forward(network, x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    if d.ndim != 1 : d = np.argmax(d, axis=1)\n",
        "    accuracy = np.sum(y == d) / float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # ランダムにバッチを取得    \n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    # ミニバッチに対応する教師訓練画像データを取得    \n",
        "    x_batch = x_train[batch_mask]\n",
        "    # ミニバッチに対応する訓練正解ラベルデータを取得する\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "\n",
        "    \n",
        "    z1, z2, y = forward(network, x_batch)\n",
        "    grad = backward(x_batch, d_batch, z1, z2, y)\n",
        "\n",
        "    if (i+1)%plot_interval==0:\n",
        "        accr_test = accuracy(x_test, d_test)\n",
        "        accuracies_test.append(accr_test)\n",
        "        \n",
        "        accr_train = accuracy(x_batch, d_batch)\n",
        "        accuracies_train.append(accr_train)\n",
        "\n",
        "#        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "#        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n",
        "        \n",
        "    # パラメータに勾配適用\n",
        "    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n",
        "        network[key]  -= learning_rate * grad[key]\n",
        "\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSOmJe2eijmZ",
        "colab_type": "text"
      },
      "source": [
        "# 学習率最適化手法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiqtrii78hQ2",
        "colab_type": "text"
      },
      "source": [
        "## [try2 ] \n",
        "\n",
        "活性化関数と重みの初期化方法を変更して違いを見てみよう\n",
        "\n",
        "\n",
        "MomentumをもとにAdaGradを作ってみよう\n",
        "θ = 1e-4 とする\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7wX3VOHpoir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('/content/drive/My Drive/Pythonライブラリ基礎講座/DNN_code_colab_ver200425/lesson_2')\n",
        "from multi_layer_net import MultiLayerNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8QnqFSNv5Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AdaGradを作ってみよう\n",
        "# データの読み込み\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(\"データ読み込み完了\")\n",
        "\n",
        "# batch_normalizationの設定 ================================\n",
        "use_batchnorm = True\n",
        "#use_batchnorm = False\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n",
        "                       use_batchnorm=use_batchnorm)\n",
        "\n",
        "iters_num = 1000\n",
        "# iters_num = 500 # 処理を短縮\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "# AdaGradでは不必要\n",
        "# =============================\n",
        "\n",
        "# momentum = 0.9 \n",
        "\n",
        "# =============================\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval=10\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "    # 勾配\n",
        "    grad = network.gradient(x_batch, d_batch)\n",
        "    if i == 0:\n",
        "        h = {}\n",
        "    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n",
        "            \n",
        "        # 変更しよう  \n",
        "        # ===========================================\n",
        "        if i == 0:\n",
        "          h[key] = np.full_like(network.params[key], 1e-4)\n",
        "        else:\n",
        "          h[key] += np.square(grad[key])\n",
        "\n",
        "        network.params[key] -= learning_rate * grad[key]/(np.sqrt(h[key]))\n",
        "        # ===========================================\n",
        "        \n",
        "        loss = network.loss(x_batch, d_batch)\n",
        "        train_loss_list.append(loss)\n",
        "        \n",
        "    if (i + 1) % plot_interval == 0:\n",
        "        accr_test = network.accuracy(x_test, d_test)\n",
        "        accuracies_test.append(accr_test)        \n",
        "        accr_train = network.accuracy(x_batch, d_batch)\n",
        "        accuracies_train.append(accr_train)\n",
        "\n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n",
        "        \n",
        "        \n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hIIVRL8guHX",
        "colab_type": "text"
      },
      "source": [
        "## [Try3] バッチ正規化をして変化を見てみよう\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBqBItuk8gpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# データの読み込み\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(\"データ読み込み完了\")\n",
        "\n",
        "# batch_normalizationの設定 ================================\n",
        "use_batchnorm = True\n",
        "#use_batchnorm = False\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.1,\n",
        "                       use_batchnorm=use_batchnorm)\n",
        "\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval=10\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "    # 勾配\n",
        "    grad = network.gradient(x_batch, d_batch)\n",
        "    if i == 0:\n",
        "        m = {}\n",
        "        v = {}\n",
        "    \n",
        "    # learning rate を再定義するのがポイント\n",
        "    learning_rate_t  = learning_rate * np.sqrt(1.0 - beta2 ** (i + 1)) / (1.0 - beta1 ** (i + 1))    \n",
        "    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n",
        "        if i == 0:\n",
        "            m[key] = np.zeros_like(network.params[key])\n",
        "            v[key] = np.zeros_like(network.params[key])\n",
        "            \n",
        "        m[key] += (1 - beta1) * (grad[key] - m[key])\n",
        "        v[key] += (1 - beta2) * (grad[key] ** 2 - v[key])            \n",
        "        network.params[key] -= learning_rate_t * m[key] / (np.sqrt(v[key]) + 1e-7)                \n",
        "        \n",
        "        \n",
        "    if (i + 1) % plot_interval == 0:\n",
        "        accr_test = network.accuracy(x_test, d_test)\n",
        "        accuracies_test.append(accr_test)        \n",
        "        accr_train = network.accuracy(x_batch, d_batch)\n",
        "        accuracies_train.append(accr_train)\n",
        "        loss = network.loss(x_batch, d_batch)\n",
        "        train_loss_list.append(loss)        \n",
        "        \n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n",
        "                \n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6an8y1Fj8gtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KlkDeIf9oRQ",
        "colab_type": "text"
      },
      "source": [
        "# 過学習\n",
        "\n",
        "結果と考察\n",
        "\n",
        "Weight Decay Lambda は小さすぎると過学習が起き、大きすぎると正則化の強度は強くなるが早めに収束してしまって未学習が起きる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTS3LOybvCpD",
        "colab_type": "text"
      },
      "source": [
        "## [try4] weigth_decay_lambdaの値を変更して正則化の強さを確認しよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3iV9LRjDRnv",
        "colab_type": "text"
      },
      "source": [
        "## L1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIy_UGt-8gxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\n",
        "\n",
        "print(\"データ読み込み完了\")\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:300]\n",
        "d_train = d_train[:300]\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\n",
        "\n",
        "\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate=0.1\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval=10\n",
        "hidden_layer_num = network.hidden_layer_num\n",
        "\n",
        "# 正則化強度設定 ======================================\n",
        "weight_decay_lambda = 0.005\n",
        "# =================================================\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "    grad = network.gradient(x_batch, d_batch)\n",
        "    weight_decay = 0\n",
        "    \n",
        "    for idx in range(1, hidden_layer_num+1):\n",
        "        grad['W' + str(idx)] = network.layers['Affine' + str(idx)].dW + weight_decay_lambda * np.sign(network.params['W' + str(idx)])\n",
        "        grad['b' + str(idx)] = network.layers['Affine' + str(idx)].db\n",
        "        network.params['W' + str(idx)] -= learning_rate * grad['W' + str(idx)]\n",
        "        network.params['b' + str(idx)] -= learning_rate * grad['b' + str(idx)]        \n",
        "        weight_decay += weight_decay_lambda * np.sum(np.abs(network.params['W' + str(idx)]))\n",
        "\n",
        "    loss = network.loss(x_batch, d_batch) + weight_decay\n",
        "    train_loss_list.append(loss)        \n",
        "        \n",
        "    if (i+1) % plot_interval == 0:\n",
        "        accr_train = network.accuracy(x_train, d_train)\n",
        "        accr_test = network.accuracy(x_test, d_test)\n",
        "        accuracies_train.append(accr_train)\n",
        "        accuracies_test.append(accr_test)\n",
        "        \n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \n",
        "                \n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--W1QtyHvOQP",
        "colab_type": "text"
      },
      "source": [
        "## [try] dropout_ratioの値を変更してみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwaCzFf3-KdD",
        "colab_type": "text"
      },
      "source": [
        "## ドロップアウト\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTsEalEe-Kwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_as6lRM-UtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from common import optimizer\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True)\n",
        "\n",
        "print(\"データ読み込み完了\")\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:300]\n",
        "d_train = d_train[:300]\n",
        "\n",
        "# ドロップアウト設定 ======================================\n",
        "use_dropout = True\n",
        "dropout_ratio = 0.3\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
        "                        weight_decay_lambda=weight_decay_lambda, use_dropout = use_dropout, dropout_ratio = dropout_ratio)\n",
        "#optimizer = optimizer.SGD(learning_rate=0.01)\n",
        "# optimizer = optimizer.Momentum(learning_rate=0.01, momentum=0.9)\n",
        "# optimizer = optimizer.AdaGrad(learning_rate=0.01)\n",
        "optimizer = optimizer.Adam()\n",
        "\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval=10\n",
        "\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    d_batch = d_train[batch_mask]\n",
        "\n",
        "    grad = network.gradient(x_batch, d_batch)\n",
        "    optimizer.update(network.params, grad)\n",
        "\n",
        "    loss = network.loss(x_batch, d_batch)\n",
        "    train_loss_list.append(loss)    \n",
        "    \n",
        "    if (i+1) % plot_interval == 0:\n",
        "        accr_train = network.accuracy(x_train, d_train)\n",
        "        accr_test = network.accuracy(x_test, d_test)\n",
        "        accuracies_train.append(accr_train)\n",
        "        accuracies_test.append(accr_test)\n",
        "\n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))        \n",
        "        \n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Knfr8_vVCr",
        "colab_type": "text"
      },
      "source": [
        "## [try] optimizerとdropout_ratioの値を変更してみよう\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-6WZ8oHvWKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C_dMvzavWUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjGtvvpR-XD-",
        "colab_type": "text"
      },
      "source": [
        "# CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puBN2Qgyvd9B",
        "colab_type": "text"
      },
      "source": [
        "## [try] im2colの処理を確認しよう\n",
        "・関数内でtransposeの処理をしている行をコメントアウトして下のコードを実行してみよう<br>\n",
        "・input_dataの各次元のサイズやフィルターサイズ・ストライド・パディングを変えてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMiS-IEpvisk",
        "colab_type": "text"
      },
      "source": [
        "## [try] col2imの処理を確認しよう\n",
        "・im2colの確認で出力したcolをimageに変換して確認しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_cxj2tXxMZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from common import layers\n",
        "from common import optimizer\n",
        "from data.mnist import load_mnist\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A_G_Cvovw1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "input_data: 入力値\n",
        "filter_h: フィルターの高さ\n",
        "filter_w: フィルターの横幅\n",
        "stride: ストライド\n",
        "pad: パディング\n",
        "'''\n",
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    # N: number, C: channel, H: height, W: width\n",
        "    N, C, H, W = input_data.shape\n",
        "    # 切り捨て除算\n",
        "    out_h = (H + 2 * pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2 * pad - filter_w)//stride + 1\n",
        "\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride * out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride * out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3) # (N, C, filter_h, filter_w, out_h, out_w) -> (N, filter_w, out_h, out_w, C, filter_h)    \n",
        "    \n",
        "    col = col.reshape(N * out_h * out_w, -1)\n",
        "    return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aX00yh0vw6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "b7ce7b7c-8fac-4e6a-da54-9f165b512ce2"
      },
      "source": [
        "# im2colの処理確認\n",
        "input_data = np.random.rand(2, 1, 4, 4)*100//1 # number, channel, height, widthを表す\n",
        "print('========== input_data ===========\\n', input_data)\n",
        "print('==============================')\n",
        "filter_h = 3\n",
        "filter_w = 3\n",
        "stride = 1\n",
        "pad = 0\n",
        "col = im2col(input_data, filter_h=filter_h, filter_w=filter_w, stride=stride, pad=pad)\n",
        "print('============= col ==============\\n', col)\n",
        "print('==============================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== input_data ===========\n",
            " [[[[40. 76. 12. 62.]\n",
            "   [40. 23. 20.  3.]\n",
            "   [ 9. 38. 30. 61.]\n",
            "   [65. 66. 77.  6.]]]\n",
            "\n",
            "\n",
            " [[[93.  4. 19. 67.]\n",
            "   [10. 11.  9. 81.]\n",
            "   [68. 96. 75. 74.]\n",
            "   [26. 69. 82. 92.]]]]\n",
            "==============================\n",
            "============= col ==============\n",
            " [[40. 76. 12. 40. 23. 20.  9. 38. 30.]\n",
            " [76. 12. 62. 23. 20.  3. 38. 30. 61.]\n",
            " [40. 23. 20.  9. 38. 30. 65. 66. 77.]\n",
            " [23. 20.  3. 38. 30. 61. 66. 77.  6.]\n",
            " [93.  4. 19. 10. 11.  9. 68. 96. 75.]\n",
            " [ 4. 19. 67. 11.  9. 81. 96. 75. 74.]\n",
            " [10. 11.  9. 68. 96. 75. 26. 69. 82.]\n",
            " [11.  9. 81. 96. 75. 74. 69. 82. 92.]]\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6cqMJdhvw_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ２次元配列を画像データに変換\n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    # N: number, C: channel, H: height, W: width\n",
        "    N, C, H, W = input_shape\n",
        "    # 切り捨て除算    \n",
        "    out_h = (H + 2 * pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2 * pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2) # (N, filter_h, filter_w, out_h, out_w, C)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride * out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride * out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwPvoKgNwK7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "92d9c3e3-aac0-4379-f2c7-224535b371ae"
      },
      "source": [
        "# ここにcol2imでの処理を書こう\n",
        "img = col2im(col, input_shape=input_data.shape, filter_h=filter_h, filter_w=filter_w, stride=stride, pad=pad)\n",
        "print(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 40. 152.  24.  62.]\n",
            "   [ 80.  92.  80.   6.]\n",
            "   [ 18. 152. 120. 122.]\n",
            "   [ 65. 132. 154.   6.]]]\n",
            "\n",
            "\n",
            " [[[ 93.   8.  38.  67.]\n",
            "   [ 20.  44.  36. 162.]\n",
            "   [136. 384. 300. 148.]\n",
            "   [ 26. 138. 164.  92.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCaSRBIGwmuO",
        "colab_type": "text"
      },
      "source": [
        "## [try] DoubleConvNetをアレンジしよう\n",
        "pooling層を一つ減らしたものに変えてみよう<br>\n",
        "conv - relu - conv - relu - pool - affine - relu - affine - softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkH3t6IgAJv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e91ca73a-e589-43a7-a974-54238d288d87"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCP8pjCW0eyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Pythonライブラリ基礎講座/DNN_code_colab_ver200425')\n",
        "sys.path.append('/content/drive/My Drive/Pythonライブラリ基礎講座/DNN_code_colab_ver200425/lesson_2')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hote-oQ7AGM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFPIt9ud0Z-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from common import layers\n",
        "from common import optimizer\n",
        "from data.mnist import load_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DoubleConvNet:\n",
        "    # conv - relu - conv - relu - pool - affine - relu - affine - softmax\n",
        "    def __init__(self, input_dim=(1, 28, 28),\n",
        "                 conv_param_1={'filter_num':10, 'filter_size':7, 'pad':1, 'stride':1},\n",
        "                 conv_param_2={'filter_num':20, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 hidden_size=50, output_size=10, weight_init_std=0.01):\n",
        "        conv_output_size_1 = (input_dim[1] - conv_param_1['filter_size'] + 2 * conv_param_1['pad']) / conv_param_1['stride'] + 1\n",
        "        conv_output_size_2 = (conv_output_size_1 - conv_param_2['filter_size'] + 2 * conv_param_2['pad']) / conv_param_2['stride'] + 1        \n",
        "        pool_output_size = int(conv_param_2['filter_num'] * (conv_output_size_2 / 2) * (conv_output_size_2 / 2))        \n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(conv_param_1['filter_num'], input_dim[0], conv_param_1['filter_size'], conv_param_1['filter_size'])\n",
        "        self.params['b1'] = np.zeros(conv_param_1['filter_num'])\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(conv_param_2['filter_num'], conv_param_1['filter_num'], conv_param_2['filter_size'], conv_param_2['filter_size'])\n",
        "        self.params['b2'] = np.zeros(conv_param_2['filter_num'])\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
        "        self.params['b3'] = np.zeros(hidden_size)\n",
        "        self.params['W4'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b4'] = np.zeros(output_size)\n",
        "        # レイヤの生成\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Conv1'] = layers.Convolution(self.params['W1'], self.params['b1'], conv_param_1['stride'], conv_param_1['pad'])\n",
        "        self.layers['Relu1'] = layers.Relu()\n",
        "        self.layers['Conv2'] = layers.Convolution(self.params['W2'], self.params['b2'], conv_param_2['stride'], conv_param_2['pad'])\n",
        "        self.layers['Relu2'] = layers.Relu()\n",
        "        self.layers['Pool1'] = layers.Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "        self.layers['Affine1'] = layers.Affine(self.params['W3'], self.params['b3'])\n",
        "        self.layers['Relu3'] = layers.Relu()\n",
        "        self.layers['Affine2'] = layers.Affine(self.params['W4'], self.params['b4'])\n",
        "        self.last_layer = layers.SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        for key in self.layers.keys():\n",
        "            x = self.layers[key].forward(x)\n",
        "        return x\n",
        "        \n",
        "    def loss(self, x, d):\n",
        "        y = self.predict(x)\n",
        "        return self.last_layer.forward(y, d)\n",
        "\n",
        "    def accuracy(self, x, d, batch_size=100):\n",
        "        if d.ndim != 1 : d = np.argmax(d, axis=1)\n",
        "        \n",
        "        acc = 0.0\n",
        "        \n",
        "        for i in range(int(x.shape[0] / batch_size)):\n",
        "            tx = x[i*batch_size:(i+1)*batch_size]\n",
        "            td = d[i*batch_size:(i+1)*batch_size]\n",
        "            y = self.predict(tx)\n",
        "            y = np.argmax(y, axis=1)\n",
        "            acc += np.sum(y == td) \n",
        "        \n",
        "        return acc / x.shape[0]\n",
        "\n",
        "    def gradient(self, x, d):\n",
        "        # forward\n",
        "        self.loss(x, d)\n",
        "        \n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "        layers = list(self.layers.values())\n",
        "        \n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 設定\n",
        "        grad = {}\n",
        "        grad['W1'], grad['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
        "        grad['W2'], grad['b2'] = self.layers['Conv2'].dW, self.layers['Conv2'].db        \n",
        "        grad['W3'], grad['b3'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grad['W4'], grad['b4'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grad"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkW6oyow0s6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "outputId": "8ff8fca5-65d6-4e3e-fe9d-111841a64e15"
      },
      "source": [
        "# データの読み込み\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(flatten=False)\n",
        "\n",
        "print(\"データ読み込み完了\")\n",
        "# 処理に時間のかかる場合はデータを削減 \n",
        "x_train, d_train = x_train[:5000], d_train[:5000]\n",
        "x_test, d_test = x_test[:1000], d_test[:1000]\n",
        "\n",
        "\n",
        "network = DoubleConvNet(input_dim=(1,28,28), \n",
        "                          conv_param_1={'filter_num':10, 'filter_size':7, 'pad':1, 'stride':1},\n",
        "                          conv_param_2={'filter_num':20, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                          hidden_size=100, output_size=10, weight_init_std=0.01)\n",
        "\n",
        "optimizer = optimizer.Adam()\n",
        "\n",
        "# 時間がかかるため100に設定\n",
        "iters_num = 200\n",
        "#iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "\n",
        "train_loss_list = []\n",
        "accuracies_train = []\n",
        "accuracies_test = []\n",
        "\n",
        "plot_interval=10\n",
        "\n",
        "\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    d_batch = d_train[batch_mask]\n",
        "    \n",
        "    grad = network.gradient(x_batch, d_batch)\n",
        "    optimizer.update(network.params, grad)\n",
        "    loss = network.loss(x_batch, d_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if (i+1) % plot_interval == 0:\n",
        "        accr_train = network.accuracy(x_train, d_train)\n",
        "        accr_test = network.accuracy(x_test, d_test)\n",
        "        accuracies_train.append(accr_train)\n",
        "        accuracies_test.append(accr_test)\n",
        "        \n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "plt.plot(lists, accuracies_test,  label=\"test set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.xlabel(\"count\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "データ読み込み完了\n",
            "Generation: 10. 正答率(トレーニング) = 0.3362\n",
            "                : 10. 正答率(テスト) = 0.329\n",
            "Generation: 20. 正答率(トレーニング) = 0.4236\n",
            "                : 20. 正答率(テスト) = 0.444\n",
            "Generation: 30. 正答率(トレーニング) = 0.6294\n",
            "                : 30. 正答率(テスト) = 0.611\n",
            "Generation: 40. 正答率(トレーニング) = 0.7456\n",
            "                : 40. 正答率(テスト) = 0.721\n",
            "Generation: 50. 正答率(トレーニング) = 0.8152\n",
            "                : 50. 正答率(テスト) = 0.778\n",
            "Generation: 60. 正答率(トレーニング) = 0.8224\n",
            "                : 60. 正答率(テスト) = 0.774\n",
            "Generation: 70. 正答率(トレーニング) = 0.8228\n",
            "                : 70. 正答率(テスト) = 0.787\n",
            "Generation: 80. 正答率(トレーニング) = 0.8614\n",
            "                : 80. 正答率(テスト) = 0.819\n",
            "Generation: 90. 正答率(トレーニング) = 0.879\n",
            "                : 90. 正答率(テスト) = 0.836\n",
            "Generation: 100. 正答率(トレーニング) = 0.877\n",
            "                : 100. 正答率(テスト) = 0.842\n",
            "Generation: 110. 正答率(トレーニング) = 0.8874\n",
            "                : 110. 正答率(テスト) = 0.846\n",
            "Generation: 120. 正答率(トレーニング) = 0.8898\n",
            "                : 120. 正答率(テスト) = 0.862\n",
            "Generation: 130. 正答率(トレーニング) = 0.9044\n",
            "                : 130. 正答率(テスト) = 0.874\n",
            "Generation: 140. 正答率(トレーニング) = 0.896\n",
            "                : 140. 正答率(テスト) = 0.87\n",
            "Generation: 150. 正答率(トレーニング) = 0.9008\n",
            "                : 150. 正答率(テスト) = 0.873\n",
            "Generation: 160. 正答率(トレーニング) = 0.9176\n",
            "                : 160. 正答率(テスト) = 0.881\n",
            "Generation: 170. 正答率(トレーニング) = 0.916\n",
            "                : 170. 正答率(テスト) = 0.888\n",
            "Generation: 180. 正答率(トレーニング) = 0.9168\n",
            "                : 180. 正答率(テスト) = 0.88\n",
            "Generation: 190. 正答率(トレーニング) = 0.9086\n",
            "                : 190. 正答率(テスト) = 0.879\n",
            "Generation: 200. 正答率(トレーニング) = 0.9268\n",
            "                : 200. 正答率(テスト) = 0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}